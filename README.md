### Инструкция по тестированию и оценке качества моделей на задаче извлечения имен (ФИО) из текста

#### Описание проекта

Этот проект реализует сервис для извлечения имен, фамилий и отчеств (ФИО) из текста с использованием различных языковых моделей (LLM). Тексты отправляются в модели для обработки, а результатом является список найденных сущностей с указанием их типа и позиции в тексте.

#### Используемые модели

В проекте протестированы следующие модели:
1. **just-ai/openai-proxy/gpt-4o**
2. **just-ai/vllm-qwen2-72b-awq**
3. **just-ai/vllm-llama3.1-70b-4q**
4. **just-ai/gemini**

#### Используемый датасет

Для оценки качества моделей использовался датасет **nerus**, предоставляемый по ссылке:
- [nerus на GitHub](https://github.com/natasha/nerus)

Этот датасет содержит разметку именованных сущностей (включая персоны, организации и локации) в тексте, что позволяет эффективно оценить производительность моделей при извлечении ФИО.

#### Описание файла `main.py`

Файл `main.py` содержит реализацию сервиса, который работает на основе `mlp_sdk`. Основные компоненты:
- **PredictRequest**: Модель данных для входного запроса. Принимает список текстов для обработки.
- **PredictResponse**: Модель данных для ответа. Возвращает список найденных сущностей.
- **FioExtractionService**: Основной класс для обработки запросов. Содержит методы для:
  - Отправки текста в LLM модель.
  - Обработки ответа от модели, извлечения сущностей и их позиций в тексте.
  - Валидации длины входного текста (не более 1000 символов).
  - Обработки ошибок запроса.

#### Формат запроса и ответа

**Пример запроса**:

```json
{
  "texts": [
    "в семье Распутиных"
  ]
}
```

**Пример ответа**:

```json
{
  "entities_list": [
    {
      "entities": [
        {
          "value": "Распутиных",
          "entity_type": "PERSON",
          "span": {
            "start_index": 8,
            "end_index": 18
          },
          "entity": "Распутиных",
          "source_type": "gpt-4o"
        }
      ]
    }
  ]
}
```

#### Описание тестирования

Тестирование было проведено на выборке текстов из датасета **nerus** с заготовленым промптом.

#### Результаты тестирования моделей

1. **Модель**: just-ai/openai-proxy/gpt-4o
   - **Precision**: 0.9867
   - **Recall**: 0.9750
   - **F1-Score**: 0.9780
   - **Скорость**: 102.14 символов/сек

2. **Модель**: just-ai/vllm-qwen2-72b-awq
   - **Precision**: 0.2920
   - **Recall**: 0.2820
   - **F1-Score**: 0.2854
   - **Скорость**: 98.60 символов/сек

3. **Модель**: just-ai/vllm-llama3.1-70b-4q
   - **Precision**: 0.3325
   - **Recall**: 0.3175
   - **F1-Score**: 0.3225
   - **Скорость**: 119.15 символов/сек

4. **Модель**: just-ai/gemini
   - **Precision**: 0.4100
   - **Recall**: 0.4350
   - **F1-Score**: 0.4170
   - **Скорость**: 43.74 символов/сек

#### Оценка производительности

- **Лучшие результаты по точности и полноте** показала модель **just-ai/openai-proxy/gpt-4o**, которая достигла высоких значений Precision и Recall.
- **Модели vllm-qwen2-72b-awq** и **vllm-llama3.1-70b-4q** продемонстрировали низкие результаты по F1-Score, но показали более высокую скорость обработки текста.
- **Модель gemini** показала сбалансированные показатели Precision и Recall, однако скорость её работы значительно ниже по сравнению с другими моделями.

#### Формат запроса

**Ожидаемый ответ**:
   ```json
   {
     "entities_list": [
       {
         "entities": [
           {
             "value": "Распутиных",
             "entity_type": "PERSON",
             "span": {
               "start_index": 8,
               "end_index": 18
             },
             "entity": "Распутиных",
             "source_type": "gpt-4o"
           }
         ]
       }
     ]
   }
   ```

### Описание типовых ошибок и возможных причин снижения точности

#### 1. **Ошибки классификации сущностей**
   - Некоторые модели могут ошибочно интерпретировать слова в тексте как имена, фамилии или отчества, хотя они таковыми не являются.
   - Это может происходить из-за того, что модели могут воспринимать **контекст** или **схожесть слов** как индикатор имени. Например, при наличии малораспространённых имен или слов, которые могут быть приняты за имена, модель ошибочно их классифицирует как `PERSON`.

   **Пример**: Слово "Олегов" может быть интерпретировано как отчество, хотя в тексте оно использовано как фамилия.

#### 2. **Ошибки в распознавании сложных имен и фамилий**
   - Модели, особенно менее мощные, могут ошибаться при распознавании сложных или многосоставных имен, таких как двойные фамилии или иностранные имена, используемые в русскоязычном тексте.
   - Это связано с тем, что такие структуры могут не вписываться в распространённые паттерны имен, которые были использованы в обучении моделей.

   **Пример**: Фамилии типа "Ван дер Виль" или имена с несколькими компонентами могут быть частично пропущены или неправильно сегментированы.

#### 3. **Чувствительность к промптам**
   - У LLM моделей высокая чувствительность к промптам (инструкциям, которые передаются модели). Разные модели могут по-разному интерпретировать один и тот же промпт, и точность работы может зависеть от точности формулировки запроса.
   - **Оптимизация промпта** может значительно улучшить результат. Например, если в промпте явно указать на необходимость извлечения только ФИО, то точность может быть выше, чем если оставить запрос более обобщённым.

   **Пример**: Один и тот же текст может давать разные результаты в зависимости от того, как сформулирован промпт. Например, добавление указания на точность формы имен может улучшить результаты.

#### 4. **Лингвистические ограничения**
   - Некоторые модели, такие как **just-ai/vllm-qwen2-72b-awq**, могут быть частично настроены на работу с англоязычными текстами. Это может приводить к снижению точности при работе с русскоязычными текстами, так как модель может использовать неверные паттерны для распознавания имен.
   - **Языковые ограничения** могут приводить к тому, что модель не корректно обрабатывает склонения имен и фамилий в русском языке или не распознает русские отчества.

   **Пример**: Модель может неправильно распознать "Андрея" как имя в одном контексте и не как имя в другом, особенно если контекст сложен или малознаком модели.

#### 5. **Контекстная неопределенность**
   - Модели могут ошибаться в случаях, когда имя в тексте встречается в неоднозначном контексте или может быть истолковано по-разному.
   - **Контекстная неопределенность** возникает, когда модели сталкиваются с именами, которые могут быть схожи с нарицательными словами или другими типами сущностей. Это приводит к снижению точности, так как модель может ошибочно принять часть текста за имя, хотя это не так.

   **Пример**: В предложении "Павел вошел в реку", модель может не понять, что "Павел" — это имя, а не какое-то нарицательное слово, если контекст не дает четкой информации.


## License

This project is licensed under Apache License 2.0.
